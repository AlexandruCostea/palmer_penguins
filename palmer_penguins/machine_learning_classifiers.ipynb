{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f01fbd-bb9a-43e3-b2f9-5fa159333afb",
   "metadata": {},
   "source": [
    "# Palmer Penguins Classification with Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b0361-7ba4-4259-91bf-6c952b91569b",
   "metadata": {},
   "source": [
    "This notebook aims to explore the Palmer Penguins dataset and develop classification models capable of accurately predicting penguin species based on various morphological measurements and environmental factors. The project encompasses a step-by-step guide, covering data preprocessing, hyperparameter tuning, and model building processes.\n",
    "\n",
    "The project focuses on the following key aspects:\n",
    "\n",
    " 1) <b>Data Management and Preprocessing</b>: Processing the dataset to transform it into a format suitable for model training. This involves handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "\n",
    " 2) <b>Hyperparameter Tuning</b>: Utilizing <b>*Grid Search Cross Validation*</b> to find the optimal hyperparameters for both the <b>K-Nearest-Neighbor (KNN)</b> and <b>Decision Tree</b> models. This ensures that the models are trained with the most effective parameters for achieving high classification accuracy.\n",
    "\n",
    " 3) <b>Model Building</b>: Constructing classification models using the best hyperparameters identified during the tuning phase. The notebook outlines the steps for training and testing these models, evaluating their performance, and comparing their effectiveness in predicting penguin species.\n",
    "\n",
    "By addressing these objectives, the notebook provides a comprehensive approach to solving the Palmer Penguins classification problem, guiding users through the entire process from data preprocessing to model implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536e871-cc21-4034-b275-8f15f324e618",
   "metadata": {},
   "source": [
    "Before diving into the project, we'll import the necessary libraries. We'll utilize Pandas to create a DataFrame for the Palmer Penguins dataset, scikit-learn for building the classification models, and Joblib for saving the trained models.\n",
    "\n",
    "Let's proceed by importing these libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a41e39-bd62-4e4c-ace5-7fa3a4b519aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a76b1d-89e8-4ba1-88ae-bdc131be68bd",
   "metadata": {},
   "source": [
    "We load the Palmer Penguins dataset from a CSV file using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae89576-2de8-4134-9db7-8b7921c99d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0       Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1       Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2       Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3       Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4       Adelie  Torgersen            36.7           19.3              193.0   \n",
       "..         ...        ...             ...            ...                ...   \n",
       "339  Chinstrap      Dream            55.8           19.8              207.0   \n",
       "340  Chinstrap      Dream            43.5           18.1              202.0   \n",
       "341  Chinstrap      Dream            49.6           18.2              193.0   \n",
       "342  Chinstrap      Dream            50.8           19.0              210.0   \n",
       "343  Chinstrap      Dream            50.2           18.7              198.0   \n",
       "\n",
       "     body_mass_g     sex  year  \n",
       "0         3750.0    male  2007  \n",
       "1         3800.0  female  2007  \n",
       "2         3250.0  female  2007  \n",
       "3            NaN     NaN  2007  \n",
       "4         3450.0  female  2007  \n",
       "..           ...     ...   ...  \n",
       "339       4000.0    male  2009  \n",
       "340       3400.0  female  2009  \n",
       "341       3775.0    male  2009  \n",
       "342       4100.0    male  2009  \n",
       "343       3775.0  female  2009  \n",
       "\n",
       "[344 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('penguins.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dac8f2-bcc6-4811-a7cb-54d86e1524fc",
   "metadata": {},
   "source": [
    "Upon inspection, we can see that the dataset contains rows with missing values. To ensure the integrity of our analysis and model training process, it's imperative to address these missing values by removing them from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb1bf7c-3da9-49a8-9cd4-7b7ccf1ee7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0       Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1       Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2       Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4       Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5       Adelie  Torgersen            39.3           20.6              190.0   \n",
       "..         ...        ...             ...            ...                ...   \n",
       "339  Chinstrap      Dream            55.8           19.8              207.0   \n",
       "340  Chinstrap      Dream            43.5           18.1              202.0   \n",
       "341  Chinstrap      Dream            49.6           18.2              193.0   \n",
       "342  Chinstrap      Dream            50.8           19.0              210.0   \n",
       "343  Chinstrap      Dream            50.2           18.7              198.0   \n",
       "\n",
       "     body_mass_g     sex  year  \n",
       "0         3750.0    male  2007  \n",
       "1         3800.0  female  2007  \n",
       "2         3250.0  female  2007  \n",
       "4         3450.0  female  2007  \n",
       "5         3650.0    male  2007  \n",
       "..           ...     ...   ...  \n",
       "339       4000.0    male  2009  \n",
       "340       3400.0  female  2009  \n",
       "341       3775.0    male  2009  \n",
       "342       4100.0    male  2009  \n",
       "343       3775.0  female  2009  \n",
       "\n",
       "[333 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_cleared = dataframe.dropna()\n",
    "dataframe_cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09fa28-b864-416f-bcef-89ecd298acc3",
   "metadata": {},
   "source": [
    "The next step is to transform categorical variables into a numerical format suitable for model training. This process involves assigning numerical codes to represent different categories within each categorical feature. By encoding categorical features, we ensure compatibility with machine learning algorithms that require numerical input, thus enabling effective utilization of these features in our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d7202f-9e8b-46d3-867f-61172f564aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0          1       2            39.1           18.7              181.0   \n",
       "1          1       2            39.5           17.4              186.0   \n",
       "2          1       2            40.3           18.0              195.0   \n",
       "4          1       2            36.7           19.3              193.0   \n",
       "5          1       2            39.3           20.6              190.0   \n",
       "..       ...     ...             ...            ...                ...   \n",
       "339        2       1            55.8           19.8              207.0   \n",
       "340        2       1            43.5           18.1              202.0   \n",
       "341        2       1            49.6           18.2              193.0   \n",
       "342        2       1            50.8           19.0              210.0   \n",
       "343        2       1            50.2           18.7              198.0   \n",
       "\n",
       "     body_mass_g  sex  year  \n",
       "0         3750.0    1  2007  \n",
       "1         3800.0    0  2007  \n",
       "2         3250.0    0  2007  \n",
       "4         3450.0    0  2007  \n",
       "5         3650.0    1  2007  \n",
       "..           ...  ...   ...  \n",
       "339       4000.0    1  2009  \n",
       "340       3400.0    0  2009  \n",
       "341       3775.0    1  2009  \n",
       "342       4100.0    1  2009  \n",
       "343       3775.0    0  2009  \n",
       "\n",
       "[333 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = ['island', 'sex']\n",
    "categorical_features = dataframe_cleared[categorical_columns]\n",
    "\n",
    "dataframe_encoded = dataframe_cleared.copy()\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    dataframe_encoded[col] = encoder.fit_transform(dataframe_cleared[col])\n",
    "\n",
    "species_codes = {\"Adelie\": 1, \"Chinstrap\": 2, \"Gentoo\": 3}\n",
    "dataframe_encoded['species'] = dataframe_encoded['species'].map(species_codes)\n",
    "\n",
    "dataframe_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1ea4d-143d-41ae-bd59-1d86b7a9d041",
   "metadata": {},
   "source": [
    "Now we have to scale the numerical features within the dataset to a standard range. Scaling is essential to ensure that all numerical features contribute equally to the model training process, preventing features with larger magnitudes from dominating the learning algorithm. This normalization process enhances the performance and convergence of machine learning algorithms, thereby improving the accuracy and reliability of our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc00e6b4-393c-49af-8258-2f6bbdd71457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.269091</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.298182</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.167273</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.261818</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414545</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0          1       2        0.254545       0.666667           0.152542   \n",
       "1          1       2        0.269091       0.511905           0.237288   \n",
       "2          1       2        0.298182       0.583333           0.389831   \n",
       "4          1       2        0.167273       0.738095           0.355932   \n",
       "5          1       2        0.261818       0.892857           0.305085   \n",
       "..       ...     ...             ...            ...                ...   \n",
       "339        2       1        0.861818       0.797619           0.593220   \n",
       "340        2       1        0.414545       0.595238           0.508475   \n",
       "341        2       1        0.636364       0.607143           0.355932   \n",
       "342        2       1        0.680000       0.702381           0.644068   \n",
       "343        2       1        0.658182       0.666667           0.440678   \n",
       "\n",
       "     body_mass_g  sex  year  \n",
       "0       0.291667    1     0  \n",
       "1       0.305556    0     0  \n",
       "2       0.152778    0     0  \n",
       "4       0.208333    0     0  \n",
       "5       0.263889    1     0  \n",
       "..           ...  ...   ...  \n",
       "339     0.361111    1     2  \n",
       "340     0.194444    0     2  \n",
       "341     0.298611    1     2  \n",
       "342     0.388889    1     2  \n",
       "343     0.298611    0     2  \n",
       "\n",
       "[333 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "dataframe_encoded[numerical_features] = scaler.fit_transform(dataframe_encoded[numerical_features])\n",
    "df = dataframe_encoded\n",
    "df['year'] = df['year'] - 2007\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6c6d0-346c-4d57-97b4-00977596c4f7",
   "metadata": {},
   "source": [
    "With the dataset now prepared for model processing, we proceed by separating the features from the target label, which in this case is the penguin species. We partition the data into a 70% training dataset and a 30% testing dataset. This division ensures that a sufficient portion of the data is allocated for model training, while retaining a separate portion for evaluating the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cad1ce-9293-423f-b1d7-6cde0c9ff13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['species'])\n",
    "y = df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdd4eb-1f89-4a05-8640-02c21c5f2b1f",
   "metadata": {},
   "source": [
    "We are now seeking to optimize our model's performance by finding the best hyperparameters. Specifically, we're focusing on determining the optimal number of neighbors for the K Neighbors Classifier. We utilize Grid Search Cross Validation for this task.The objective of hyperparameter tuning is to enhance the model's predictive accuracy and generalization ability.\n",
    "\n",
    "Grid Search Cross Validation systematically explores a predefined grid of hyperparameters, evaluating each combination through cross-validation. This technique splits the dataset into subsets and iteratively trains and validates the model on different portions, providing a reliable estimate of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e331127d-236b-4536-9a04-fafcd6c3f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors: 1\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]} \n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(\"Best n_neighbors:\", best_n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7a6ae-fa9a-4e45-a14b-b3a7044e3f1d",
   "metadata": {},
   "source": [
    "After determining the optimal number of neighbors through hyperparameter tuning, we proceed to create the K Neighbors Classifier model using this best parameter. Subsequently, we train the model on the training data and evaluate its performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a5b41f-ed20-4801-9dfe-f60af7f62d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=best_n_neighbors) \n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615b3d4-7138-41ab-8777-c9983541aabc",
   "metadata": {},
   "source": [
    "In the last step, we save the trained model to make it accessible for use in other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274a63a0-da45-4239-b939-d15ad8f0f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/knn_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn_model, 'models/knn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b4fe1-d6e6-42e5-b1ec-ce89d967b902",
   "metadata": {},
   "source": [
    "We iterate through the steps of hyperparameter optimization, model construction, training, testing, and model saving, this time focusing on the Decision Tree Algorithm. In this iteration, our aim is to identify the optimal maximum depth of the tree through hyperparameter tuning. Once the best hyperparameter is determined, we construct, train, evaluate, and save the Decision Tree model, ensuring its readiness for integration into other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c57d9b2-0031-41ba-a218-88e458eb51d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 4\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "param_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "print(\"Best max_depth:\", best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08e5484-8fc3-4ef8-a07f-d83c2d6385fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=best_max_depth)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e642303-577a-4723-9510-b938c72a9c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/dt_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dt_model, 'models/dt_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
